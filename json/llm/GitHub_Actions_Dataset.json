{
  "Name": "GitHub Actions Dataset for LLM Training",
  "Labeled": "Yes",
  "Time Series": "No",
  "Data Source": "Public GitHub repositories and the Gemini 2.0 Flash API",
  "Missing Values": "No",
  "Dataset Characteristics": "Generated through an automated pipeline. Each entry consists of a question about a GitHub Actions workflow and the corresponding YAML file content as the answer. The questions are generated by a cutting-edge LLM (Gemini 2.0 Flash) to be concise and relevant to the workflow's function. The data is structured as question-answer pairs, making it ideal for supervised fine-tuning.",
  "Feature Type": "Text (natural language question and YAML code)",
  "Associated Tasks": "Instruction fine-tuning, natural language understanding, code generation, code summarization, debugging, and code explanation for Large Language Models (LLMs).",
  "Number of Instances": "Variable (continuously growing)",
  "Number of Features": "6 (question, answer, source, path, url, retrieved_at)",
  "Date Donated": "Continual (the dataset is actively being populated via a GitHub Action)",
  "Source": "Automatically generated from open-source GitHub repositories and the Gemini 2.0 Flash API.",
  "Summary": "A dynamic, open-source dataset of GitHub Actions workflows, paired with LLM-generated questions. Designed for training and evaluating Large Language Models on GitHub workflow-related tasks, such as summarization, generation, and explanation.",
  "Description": "This dataset is a valuable resource for the machine learning community, providing structured data to advance LLMs' capabilities in the domain of software automation. The dataset is generated by a GitHub Actions workflow that automatically discovers public workflows, prompts the Gemini 2.0 Flash API to create a descriptive question for each, and then stores the question-answer pair. The structure of the data is a 'question-answer' format, where the question is a natural language query about the workflow's purpose, and the answer is the raw YAML code. This format is highly effective for supervised fine-tuning of LLMs for tasks like code generation and understanding.",
  "Additional Tags": [
    "LLM training",
    "fine-tuning",
    "code dataset",
    "GitHub Actions",
    "YAML",
    "CI/CD",
    "supervised learning",
    "code generation",
    "code summarization",
    "open-source",
    "Gemini 2.0 Flash"
  ],
  "References": [
    {
      "Text": "GitHub Actions Dataset Repository",
      "Link": "https://github.com/PUSHPAK-JAISWAL/Github-Actions-Dataset.git"
    },
    {
      "Text": "Gemini 2.0 Flash Model Overview",
      "Link": "https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-0-flash"
    },
    {
      "Text": "GitHub Actions Documentation",
      "Link": "https://docs.github.com/en/actions"
    }
  ]
}